{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42554f08-4b3a-42b1-a1d3-058e2e604439",
   "metadata": {},
   "source": [
    "# Variational Auto-Encoder for Molecular Generation Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c2daa62-52bc-4723-abc4-c2d5ddf22293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fce3dd-7757-4797-b1f3-51c6a58c6173",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab429459-5d68-4722-acb0-44477ee6dda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2723, 128, 32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LENGTH = 128\n",
    "DFF = 32\n",
    "\n",
    "# shape; (batch_size, length, dff)\n",
    "cb2_embeddings = np.load(\"./data/processed_cb2.npy\")\n",
    "cb2_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be44f1a3-e9c3-47c7-bc87-a6fff63ca9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1906, 128, 32, 1]), TensorShape([817, 128, 32, 1]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, x_test = train_test_split(cb2_embeddings, test_size=0.3, random_state=17)\n",
    "X_train = tf.expand_dims(X_train, axis=-1)\n",
    "x_test = tf.expand_dims(x_test, axis=-1)\n",
    "\n",
    "X_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57900d9a-3385-47cb-b6cb-c637ca5d2f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tensor):\n",
    "    tensor = tf.cast(tensor, dtype=tf.float32)\n",
    "    tensor = tf.divide( tf.subtract(tensor, tf.reduce_min(tensor)), tf.subtract(tf.reduce_max(tensor), tf.reduce_min(tensor)) )\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8621c579-dc61-4651-bd7f-699341fe35b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.50185823>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = preprocess(X_train)\n",
    "x_test = preprocess(x_test)\n",
    "\n",
    "tf.math.reduce_min(X_train), tf.math.reduce_max(X_train), tf.math.reduce_mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36608090-b2e8-4179-ba27-0d791f4f054d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.5030998>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_min(x_test), tf.math.reduce_max(x_test), tf.math.reduce_mean(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35712449-a067-49ac-b3b8-d2b22f5021c5",
   "metadata": {},
   "source": [
    "## VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4962452-92bf-47ee-ba5b-1f21f27deb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57648cfa-ae88-415d-ad5b-067366eec3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 32, 1)]         0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 64, 16, 32)           320       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 32, 8, 64)            18496     ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 16, 4, 128)           73856     ['conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 8, 2, 256)            295168    ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 4096)                 0         ['conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  524416    ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 128, 1)               0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 128, 128)             66560     ['reshape[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 16384)                0         ['lstm[0][0]']                \n",
      "                                                                                                  \n",
      " z_mean (Dense)              (None, 512)                  8389120   ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " z_log_var (Dense)           (None, 512)                  8389120   ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " sampling (Sampling)         (None, 512)                  0         ['z_mean[0][0]',              \n",
      "                                                                     'z_log_var[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 17757056 (67.74 MB)\n",
      "Trainable params: 17757056 (67.74 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MAX_ROWS = 128\n",
    "MAX_COLUMNS = 32\n",
    "latent_dim = 512\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(MAX_ROWS, MAX_COLUMNS, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2D(256, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Reshape((128, 1))(x)  # Add this line to reshape the output for LSTM\n",
    "x = layers.LSTM(128, return_sequences=True)(x)  # Apply LSTM after Conv2D and Reshape\n",
    "x = layers.Flatten()(x)  # Flatten the LSTM output to be connected to z_mean and z_log_var\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43da8a5a-b467-40c0-a2fa-315f5b73de81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 512)]             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 128, 1)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128, 128)          66560     \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 16, 4, 256)        0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTr  (None, 32, 8, 256)        590080    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2D  (None, 64, 16, 128)       295040    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2D  (None, 128, 32, 64)       73792     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2D  (None, 128, 32, 1)        577       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1091713 (4.16 MB)\n",
      "Trainable params: 1091713 (4.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(128, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((128, 1))(x)\n",
    "x = layers.LSTM(128, return_sequences=True)(x)\n",
    "x = layers.Reshape((16, 4, 256))(x)\n",
    "x = layers.Conv2DTranspose(256, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(128, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)  # Output the reconstructed input\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()\n",
    "\n",
    "\n",
    "# latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "# x = layers.Dense(MAX_ROWS // 16 * MAX_COLUMNS // 16 * 64, activation=\"relu\")(latent_inputs)\n",
    "# x = layers.Reshape((MAX_ROWS // 16, MAX_COLUMNS // 16, 64))(x)\n",
    "# x = layers.Conv2DTranspose(256, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "# x = layers.Conv2DTranspose(128, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "# x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "# x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "# decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "# decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "# decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b65287fa-2f86-42dd-abdf-3cd673ed8b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            mse = tf.keras.losses.MeanSquaredError()\n",
    "            kl = tf.keras.losses.KLDivergence()\n",
    "            reconstruction_loss = mse(data, reconstruction)\n",
    "            kl_loss = kl(data, reconstruction)\n",
    "            \n",
    "            # reconstruction_loss = tf.reduce_mean(\n",
    "            #     tf.reduce_sum(\n",
    "            #         mse(data, reconstruction), axis=(1, 2)\n",
    "            #     )\n",
    "            # )\n",
    "            # kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            # kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            \n",
    "            total_loss = reconstruction_loss + 0.15 * kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf31bb7-c36b-475c-8c91-723d32ee8bdf",
   "metadata": {},
   "source": [
    "## Loading VAE from Checkpoint\n",
    "Only run if checkpoint has been created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c81be13-6e1b-496e-af45-7918acbeb52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2913256d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.load_weights('./vae_checkpoints/trained_vae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8699d194-b76f-4e97-a074-1606eded51b4",
   "metadata": {},
   "source": [
    "## VAE Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ecb7273-c5fb-4d3a-89ad-75bbc39844c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/15 [=======================>......] - ETA: 8s - loss: 0.0158 - reconstruction_loss: 0.0174 - kl_loss: -0.0213 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [early_stopping_callback, tensorboard_callback]\n\u001b[1;32m      7\u001b[0m vae\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mlegacy\u001b[38;5;241m.\u001b[39mAdam())\n\u001b[0;32m----> 8\u001b[0m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='reconstruction_loss', patience=3, verbose=1)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "callbacks = [early_stopping_callback, tensorboard_callback]\n",
    "\n",
    "vae.compile(optimizer=keras.optimizers.legacy.Adam())\n",
    "vae.fit(X_train, epochs=50, batch_size=128, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "222775d6-a258-4770-8496-29dc522aa683",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.save_weights('./vae_checkpoints/trained_vae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231dc7a4-aeb6-4beb-9bd2-ce022911a61e",
   "metadata": {},
   "source": [
    "## Sampling Latent Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7f57e5-3be2-4be1-9c7b-0921272b4f53",
   "metadata": {},
   "source": [
    "#### Build Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "266ff0d6-8c99-4fe5-80a6-f8b7c060df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "def create_masks(inp, tar):\n",
    "  # Encoder padding mask\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 2nd attention block in the decoder.\n",
    "  # This padding mask is used to mask the encoder outputs.\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 1st attention block in the decoder.\n",
    "  # It is used to pad and mask future tokens in the input received by \n",
    "  # the decoder.\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    assert d_model % self.num_heads == 0\n",
    "    \n",
    "    self.depth = d_model // self.num_heads\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "    \n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    \n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights\n",
    "\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2\n",
    "\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attn_weights_block1, attn_weights_block2\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                            self.d_model)\n",
    "    \n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    \n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaeee68f-e094-4a3d-9731-d521194c2777",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b9b62d0-ab9b-42b3-b57c-b0798447aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 32\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "input_vocab_size = 510\n",
    "target_vocab_size = 510\n",
    "dropout_rate = 0.2\n",
    "\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33530b8d-4516-4a2a-8b8f-47961ec1e537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c175c5d5-3e31-4bc6-836e-6b8f75ff7873",
   "metadata": {},
   "source": [
    "#### Decoder Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e12457a-ce4e-48d5-bf6e-5bfda461ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "'O=C(NCc1ccccc1)c1cc2c(n(CC3N3CCOCCC)c1=O)CCCCCCC'\n",
    "'O=C(NCc1ccccc1)c1cc2c(n(CC3N3CCOCCC)c1=O)CCCCCCC'\n",
    "'O=C(NCc1ccccc1)c1cc2c(n(CC3N3CCOCCC)c1=O)CCCCCCC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd6fff65-094f-4bd1-8c93-3d0c079a867e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC=====CCCCCCC==========\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC=====CCCCCCC==========\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC=====CCCCCCC==========\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC====CCCCCCC==========\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC=====CCCCCCC==========\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC===CCCCCCC==========\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC====CCCCCCC==========\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC====CCCCCCC==========\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC=====CCCCC=C==========\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC====CCCCCCC==========\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC=====CCCCCCC==========\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC====CCCCCCC==========\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC=====CCCCCCC==========\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC=====CCCCC=C==========\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC=====CCCCCCC==========\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m smiles_string\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m500\u001b[39m):\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(decode(\u001b[43msampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m))\n",
      "Cell \u001b[0;32mIn[16], line 21\u001b[0m, in \u001b[0;36msampler\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     18\u001b[0m input_sample \u001b[38;5;241m=\u001b[39m X_train[i]\n\u001b[1;32m     19\u001b[0m input_sample \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(input_sample, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m z_mean, z_log_var, sampling \u001b[38;5;241m=\u001b[39m \u001b[43mencode_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m z_sample \u001b[38;5;241m=\u001b[39m sample_from_latent(z_mean, z_log_var)\n\u001b[1;32m     25\u001b[0m reconstructed_sample \u001b[38;5;241m=\u001b[39m decode_sample(z_sample)\n",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m, in \u001b[0;36mencode_sample\u001b[0;34m(input_sample)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_sample\u001b[39m(input_sample):\n\u001b[0;32m----> 5\u001b[0m     z_mean, z_log_var, sampling \u001b[38;5;241m=\u001b[39m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m z_mean, z_log_var, sampling\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/engine/training.py:569\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    567\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/engine/base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1149\u001b[0m ):\n\u001b[0;32m-> 1150\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/engine/functional.py:512\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_doc_inheritable\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    495\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \n\u001b[1;32m    497\u001b[0m \u001b[38;5;124;03m    In this case `call` just reapplies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_internal_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/engine/functional.py:669\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[0;32m--> 669\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_id, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    673\u001b[0m     node\u001b[38;5;241m.\u001b[39mflat_output_ids, tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(outputs)\n\u001b[1;32m    674\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/layers/rnn/base_rnn.py:556\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m inputs, initial_state, constants \u001b[38;5;241m=\u001b[39m rnn_utils\u001b[38;5;241m.\u001b[39mstandardize_args(\n\u001b[1;32m    552\u001b[0m     inputs, initial_state, constants, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_constants\n\u001b[1;32m    553\u001b[0m )\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m constants \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# input_spec to include them.\u001b[39;00m\n\u001b[1;32m    562\u001b[0m additional_inputs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/engine/base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1149\u001b[0m ):\n\u001b[0;32m-> 1150\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/layers/rnn/lstm.py:741\u001b[0m, in \u001b[0;36mLSTM.call\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    731\u001b[0m         last_output, outputs, new_h, new_c, runtime \u001b[38;5;241m=\u001b[39m gpu_lstm(\n\u001b[1;32m    732\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgpu_lstm_kwargs\n\u001b[1;32m    733\u001b[0m         )\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m         (\n\u001b[1;32m    736\u001b[0m             last_output,\n\u001b[1;32m    737\u001b[0m             outputs,\n\u001b[1;32m    738\u001b[0m             new_h,\n\u001b[1;32m    739\u001b[0m             new_c,\n\u001b[1;32m    740\u001b[0m             runtime,\n\u001b[0;32m--> 741\u001b[0m         ) \u001b[38;5;241m=\u001b[39m \u001b[43mstandard_lstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnormal_lstm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    743\u001b[0m     (\n\u001b[1;32m    744\u001b[0m         last_output,\n\u001b[1;32m    745\u001b[0m         outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    748\u001b[0m         runtime,\n\u001b[1;32m    749\u001b[0m     ) \u001b[38;5;241m=\u001b[39m lstm_with_backend_selection(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnormal_lstm_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/layers/rnn/lstm.py:981\u001b[0m, in \u001b[0;36mstandard_lstm\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask, return_sequences)\u001b[0m\n\u001b[1;32m    978\u001b[0m     h \u001b[38;5;241m=\u001b[39m o \u001b[38;5;241m*\u001b[39m tf\u001b[38;5;241m.\u001b[39mtanh(c)\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m h, [h, c]\n\u001b[0;32m--> 981\u001b[0m last_output, outputs, new_states \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43minit_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_c\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43munroll\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_major\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_major\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgo_backwards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgo_backwards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[43msequence_lengths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msequence_lengths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzero_output_for_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_output_for_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_all_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    997\u001b[0m     last_output,\n\u001b[1;32m    998\u001b[0m     outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1001\u001b[0m     gru_lstm_utils\u001b[38;5;241m.\u001b[39mruntime(gru_lstm_utils\u001b[38;5;241m.\u001b[39mRUNTIME_CPU),\n\u001b[1;32m   1002\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/backend.py:5170\u001b[0m, in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001b[0m\n\u001b[1;32m   5165\u001b[0m         new_states \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[1;32m   5166\u001b[0m             initial_states, flat_new_state\n\u001b[1;32m   5167\u001b[0m         )\n\u001b[1;32m   5168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (time \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, output_ta_t) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(new_states)\n\u001b[0;32m-> 5170\u001b[0m     final_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhile_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloop_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_ta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5173\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mwhile_loop_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5175\u001b[0m     new_states \u001b[38;5;241m=\u001b[39m final_outputs[\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m   5177\u001b[0m output_ta \u001b[38;5;241m=\u001b[39m final_outputs[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/tensorflow/python/ops/while_loop.py:499\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m    496\u001b[0m loop_var_structure \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(type_spec\u001b[38;5;241m.\u001b[39mtype_spec_from_value,\n\u001b[1;32m    497\u001b[0m                                         \u001b[38;5;28mlist\u001b[39m(loop_vars))\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cond(\u001b[38;5;241m*\u001b[39mloop_vars):\n\u001b[0;32m--> 499\u001b[0m   loop_vars \u001b[38;5;241m=\u001b[39m \u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mloop_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m try_to_pack \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loop_vars, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    501\u001b[0m     packed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/backend.py:5160\u001b[0m, in \u001b[0;36mrnn.<locals>._step\u001b[0;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[1;32m   5158\u001b[0m flat_output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(output)\n\u001b[1;32m   5159\u001b[0m ta_index_to_write \u001b[38;5;241m=\u001b[39m time \u001b[38;5;28;01mif\u001b[39;00m return_all_outputs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 5160\u001b[0m output_ta_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m   5161\u001b[0m     ta\u001b[38;5;241m.\u001b[39mwrite(ta_index_to_write, out)\n\u001b[1;32m   5162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ta, out \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(output_ta_t, flat_output)\n\u001b[1;32m   5163\u001b[0m )\n\u001b[1;32m   5165\u001b[0m new_states \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[1;32m   5166\u001b[0m     initial_states, flat_new_state\n\u001b[1;32m   5167\u001b[0m )\n\u001b[1;32m   5168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (time \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, output_ta_t) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(new_states)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/backend.py:5161\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   5158\u001b[0m flat_output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(output)\n\u001b[1;32m   5159\u001b[0m ta_index_to_write \u001b[38;5;241m=\u001b[39m time \u001b[38;5;28;01mif\u001b[39;00m return_all_outputs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   5160\u001b[0m output_ta_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m-> 5161\u001b[0m     \u001b[43mta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mta_index_to_write\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ta, out \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(output_ta_t, flat_output)\n\u001b[1;32m   5163\u001b[0m )\n\u001b[1;32m   5165\u001b[0m new_states \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[1;32m   5166\u001b[0m     initial_states, flat_new_state\n\u001b[1;32m   5167\u001b[0m )\n\u001b[1;32m   5168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (time \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, output_ta_t) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(new_states)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/tensorflow/python/util/tf_should_use.py:288\u001b[0m, in \u001b[0;36mshould_use_result.<locals>.decorated.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _add_should_use_warning(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    289\u001b[0m                                  warn_in_eager\u001b[38;5;241m=\u001b[39mwarn_in_eager,\n\u001b[1;32m    290\u001b[0m                                  error_in_function\u001b[38;5;241m=\u001b[39merror_in_function)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/tensorflow/python/ops/tensor_array_ops.py:1182\u001b[0m, in \u001b[0;36mTensorArray.write\u001b[0;34m(self, index, value, name)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;129m@tf_should_use\u001b[39m\u001b[38;5;241m.\u001b[39mshould_use_result(warn_in_eager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, index, value, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Write `value` into index `index` of the TensorArray.\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m \n\u001b[1;32m   1170\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;124;03m    ValueError: if there are more writers than specified.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1182\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_implementation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/tensorflow/python/ops/tensor_array_ops.py:852\u001b[0m, in \u001b[0;36m_EagerTensorArray.write\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See TensorArray.\"\"\"\u001b[39;00m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m name  \u001b[38;5;66;03m# not meaningful when executing eagerly.\u001b[39;00m\n\u001b[0;32m--> 852\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent()\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/tensorflow/python/ops/tensor_array_ops.py:845\u001b[0m, in \u001b[0;36m_EagerTensorArray._write\u001b[0;34m(self, index, value)\u001b[0m\n\u001b[1;32m    841\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible shape for value (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m), expected (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    842\u001b[0m                    (value\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_shape))\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer_shape:\n\u001b[0;32m--> 845\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_element_shape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor_array[index] \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/tensorflow/python/framework/tensor_shape.py:1032\u001b[0m, in \u001b[0;36mTensorShape.merge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a `TensorShape` combining the information in `self` and `other`.\u001b[39;00m\n\u001b[1;32m    997\u001b[0m \n\u001b[1;32m    998\u001b[0m \u001b[38;5;124;03mThe dimensions in `self` and `other` are merged element-wise,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;124;03m  ValueError: If `self` and `other` are not compatible.\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m other \u001b[38;5;241m=\u001b[39m as_shape(other)\n\u001b[0;32m-> 1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdims\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1033\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m other\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/tensorflow/python/framework/tensor_shape.py:908\u001b[0m, in \u001b[0;36mTensorShape.dims\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    907\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 908\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mas_dimension\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dims\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/tensorflow/python/framework/tensor_shape.py:908\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    907\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 908\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [as_dimension(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dims]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tokenizer import SmilesTokenizer\n",
    "\n",
    "def encode_sample(input_sample):\n",
    "    z_mean, z_log_var, sampling = vae.encoder(input_sample)\n",
    "    return z_mean, z_log_var, sampling\n",
    "\n",
    "def sample_from_latent(z_mean, z_log_var):\n",
    "    epsilon = tf.random.normal(tf.shape(z_mean))\n",
    "    z = z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    return z\n",
    "\n",
    "def decode_sample(z_sample):\n",
    "    reconstructed_sample = vae.decoder(z_sample)\n",
    "    return reconstructed_sample\n",
    "\n",
    "def sampler(i):\n",
    "    input_sample = X_train[i]\n",
    "    input_sample = tf.expand_dims(input_sample, axis=0)\n",
    "    \n",
    "    z_mean, z_log_var, sampling = encode_sample(input_sample)\n",
    "\n",
    "    z_sample = sample_from_latent(z_mean, z_log_var)\n",
    "    \n",
    "    reconstructed_sample = decode_sample(z_sample)\n",
    "    reconstructed_sample = tf.squeeze(reconstructed_sample, axis=-1)\n",
    "    return reconstructed_sample\n",
    "\n",
    "def decode(embedding):\n",
    "    tokenizer = SmilesTokenizer(\"./data/vocab.txt\")\n",
    "    sample_zeros = tf.zeros((1, 128))\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(sample_zeros, sample_zeros)\n",
    "\n",
    "    dec_output, _ = transformer.decoder(sample_zeros, embedding, False, combined_mask, dec_padding_mask)\n",
    "    final_output = transformer.final_layer(dec_output)\n",
    "\n",
    "    smiles_string = []\n",
    "    for token in range(128):\n",
    "        smiles_string.append( int( tf.argmax( final_output[:, token, :], axis=-1 )[0] ) )\n",
    "    smiles_string = tokenizer.decode(smiles_string).replace(' ', '')\n",
    "    smiles_string = smiles_string[:smiles_string.find('[SEP]')]\n",
    "\n",
    "    return smiles_string\n",
    "\n",
    "for i in range(500):\n",
    "    print(decode(sampler(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d21bd17f-1706-498e-8f96-72e939d22a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-12.010056  -12.201371  -11.890745  ... -11.987468  -11.95752\n",
      "   -12.05295  ]\n",
      "  [-16.562353  -16.805267  -16.272493  ... -16.537561  -16.496244\n",
      "   -16.327068 ]\n",
      "  [-21.470423  -21.515547  -21.554365  ... -21.364697  -21.69297\n",
      "   -21.427305 ]\n",
      "  ...\n",
      "  [-15.237321  -15.373925  -15.216337  ... -15.198552  -14.965597\n",
      "   -15.211064 ]\n",
      "  [-14.855588  -14.9820385 -14.84074   ... -14.81174   -14.574617\n",
      "   -14.827436 ]\n",
      "  [-14.50811   -14.626286  -14.498796  ... -14.458283  -14.214958\n",
      "   -14.480728 ]]], shape=(1, 128, 510), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tokenizer import SmilesTokenizer\n",
    "tokenizer = SmilesTokenizer(\"./data/vocab.txt\")\n",
    "\n",
    "cb2_smiles = open('./data/X_SMILES.txt', 'r')\n",
    "cb2_smiles = cb2_smiles.read().splitlines()\n",
    "sampling_smiles = cb2_smiles[ random.randint(0, len(cb2_smiles) - 1) ]\n",
    "\n",
    "sample = tokenizer.encode(sampling_smiles)\n",
    "sample = tf.keras.utils.pad_sequences([sample], maxlen=128, padding='post')\n",
    "sample = tf.constant(sample)\n",
    "sample_zeros = tf.zeros((1, 128))\n",
    "\n",
    "enc_padding_mask, combined_mask, dec_padding_mask = create_masks(sample_zeros, sample_zeros)\n",
    "enc_output = transformer.encoder(sample_zeros, False, enc_padding_mask)\n",
    "\n",
    "dec_output, _ = transformer.decoder(sample_zeros, reconstructed_sample, False, combined_mask, dec_padding_mask)\n",
    "final_output = transformer.final_layer(dec_output)\n",
    "\n",
    "# enc_padding_mask, combined_mask, dec_padding_mask = create_masks(sample, sample)\n",
    "\n",
    "# predictions, _ = transformer(sample, sample, \n",
    "#                                 False, \n",
    "#                                 enc_padding_mask, \n",
    "#                                 combined_mask, \n",
    "#                                 dec_padding_mask)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d83c5df7-f19c-44ee-a30f-eab122f63672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('O=C(NCc1ccccc1)c1cc2c(n(CC3N3CCOCCC)c1=O)CCCCCCC',\n",
       " 'CN(CC1CC1)S(=O)(=O)c1ccc(Nc2ccc(Cl)cc2Cl)cc1C(F)(F)F')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizer import SmilesTokenizer\n",
    "tokenizer = SmilesTokenizer(\"./data/vocab.txt\")\n",
    "\n",
    "preds = []\n",
    "\n",
    "for token in range(128):\n",
    "    preds.append( int( tf.argmax( predictions[:, token, :], axis=-1 )[0] ) )\n",
    "pred_smiles = tokenizer.decode(preds).replace(' ', '')\n",
    "\n",
    "pred_smiles[:pred_smiles.find('[SEP]')], sampling_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6b9148f4-3033-4008-9199-cb85e439ccb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'multi_head_attention_17' (type MultiHeadAttention).\n\nInput 0 of layer \"dense_96\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (1, 128, 32)\n\nCall arguments received by layer 'multi_head_attention_17' (type MultiHeadAttention):\n  • v=tf.Tensor(shape=(1, 128, 32), dtype=float32)\n  • k=tf.Tensor(shape=(1, 128, 32), dtype=float32)\n  • q=tf.Tensor(shape=(1, 32, 32), dtype=float32)\n  • mask=tf.Tensor(shape=(1, 1, 1, 32), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     generated_tokens \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(generated_tokens, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     32\u001b[0m     generated_strings \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(token_indices)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m \u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[70], line 17\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(embedding)\u001b[0m\n\u001b[1;32m     15\u001b[0m look_ahead_mask \u001b[38;5;241m=\u001b[39m create_look_ahead_mask(tf\u001b[38;5;241m.\u001b[39mshape(decoder_input)[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     16\u001b[0m combined_mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmaximum(look_ahead_mask, dec_padding_mask)\n\u001b[0;32m---> 17\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m last_token_logits \u001b[38;5;241m=\u001b[39m decoder_output[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m     20\u001b[0m next_token \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39margmax(last_token_logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[24], line 262\u001b[0m, in \u001b[0;36mDecoder.call\u001b[0;34m(self, x, enc_output, training, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[1;32m    259\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[0;32m--> 262\u001b[0m   x, block1, block2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdec_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mlook_ahead_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m   attention_weights[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_layer\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_block1\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m block1\n\u001b[1;32m    266\u001b[0m   attention_weights[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_layer\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_block2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m block2\n",
      "Cell \u001b[0;32mIn[24], line 189\u001b[0m, in \u001b[0;36mDecoderLayer.call\u001b[0;34m(self, x, enc_output, training, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[1;32m    186\u001b[0m attn1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(attn1, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m    187\u001b[0m out1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm1(attn1 \u001b[38;5;241m+\u001b[39m x)\n\u001b[0;32m--> 189\u001b[0m attn2, attn_weights_block2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmha2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, target_seq_len, d_model)\u001b[39;00m\n\u001b[1;32m    191\u001b[0m attn2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(attn2, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m    192\u001b[0m out2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm2(attn2 \u001b[38;5;241m+\u001b[39m out1)  \u001b[38;5;66;03m# (batch_size, target_seq_len, d_model)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[24], line 111\u001b[0m, in \u001b[0;36mMultiHeadAttention.call\u001b[0;34m(self, v, k, q, mask)\u001b[0m\n\u001b[1;32m    108\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(q)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    110\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwq(q)  \u001b[38;5;66;03m# (batch_size, seq_len, d_model)\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, seq_len, d_model)\u001b[39;00m\n\u001b[1;32m    112\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwv(v)  \u001b[38;5;66;03m# (batch_size, seq_len, d_model)\u001b[39;00m\n\u001b[1;32m    114\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_heads(q, batch_size)  \u001b[38;5;66;03m# (batch_size, num_heads, seq_len_q, depth)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'multi_head_attention_17' (type MultiHeadAttention).\n\nInput 0 of layer \"dense_96\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (1, 128, 32)\n\nCall arguments received by layer 'multi_head_attention_17' (type MultiHeadAttention):\n  • v=tf.Tensor(shape=(1, 128, 32), dtype=float32)\n  • k=tf.Tensor(shape=(1, 128, 32), dtype=float32)\n  • q=tf.Tensor(shape=(1, 32, 32), dtype=float32)\n  • mask=tf.Tensor(shape=(1, 1, 1, 32), dtype=float32)"
     ]
    }
   ],
   "source": [
    "def decode(embedding):\n",
    "    start_token = 12\n",
    "    end_token = 13\n",
    "    max_length = 128\n",
    "    batch_size = 32\n",
    "    \n",
    "    decoder_input = tf.expand_dims([start_token] * 32, 0)\n",
    "    generated_tokens = decoder_input\n",
    "\n",
    "    embedding = tf.transpose(embedding, perm=[2, 0, 1])\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        # enc_padding_mask, combined_mask, dec_padding_mask = create_masks(decoder_input, decoder_input)\n",
    "        dec_padding_mask = create_padding_mask(decoder_input)\n",
    "        look_ahead_mask = create_look_ahead_mask(tf.shape(decoder_input)[1])\n",
    "        combined_mask = tf.maximum(look_ahead_mask, dec_padding_mask)\n",
    "        decoder_output = transformer.decoder(decoder_input, embedding, False, combined_mask, dec_padding_mask)\n",
    "        \n",
    "        last_token_logits = decoder_output[:, -1, :]\n",
    "        next_token = tf.argmax(last_token_logits, axis=-1)\n",
    "        generated_tokens = tf.concat([generated_tokens, tf.expand_dims(next_token, 1)], axis=-1)\n",
    "        \n",
    "        # Stop decoding if the end-of-sequence token is generated for all samples\n",
    "        if tf.reduce_all(next_token == end_token):\n",
    "            break\n",
    "    \n",
    "        # Update the decoder input for the next step\n",
    "        decoder_input = generated_tokens\n",
    "    \n",
    "    # Remove the batch dimension from the generated tokens\n",
    "    generated_tokens = tf.squeeze(generated_tokens, axis=0)\n",
    "    generated_strings = tokenizer.decode(token_indices).replace(' ', '')\n",
    "\n",
    "decode(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaebaeb-2553-47bb-b4be-4362ea25c357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2545c00e-d9e3-46da-b453-2856e0bdf72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7c9eed-9da7-4def-b37a-cbbfe8e484f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a51d48-dc19-4a4f-9c0d-5ee8b8a641bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73aed12-b5e7-4889-b833-6cac758c6a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd94d3-7ce8-4a32-8f73-3d565b408595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e89a3c95-f909-4f88-9b42-14d8ae95ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Encode an input sample to get mean and log variance of the latent distribution\n",
    "def encode_sample(input_sample):\n",
    "    z_mean, z_log_var, sampling = vae.encoder(input_sample)\n",
    "    return z_mean, z_log_var, sampling\n",
    "\n",
    "# Step 2: Sample a point from the latent distribution using the reparameterization trick\n",
    "def sample_from_latent(z_mean, z_log_var):\n",
    "    epsilon = tf.random.normal(tf.shape(z_mean))\n",
    "    z = z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    return z\n",
    "\n",
    "# Step 3: Decode the sampled point to generate a reconstructed output\n",
    "def decode_sample(z_sample):\n",
    "    reconstructed_sample = vae.decoder(z_sample)\n",
    "    return reconstructed_sample\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have an input sample 'input_sample' (numpy array or tensor) for encoding\n",
    "input_sample = X_train[0]  # Replace with your actual input sample\n",
    "input_sample = tf.expand_dims(input_sample, axis=0)\n",
    "\n",
    "# Encode the input sample to get mean and log variance of the latent distribution\n",
    "z_mean, z_log_var, sampling = encode_sample(input_sample)\n",
    "\n",
    "# Sample a point from the latent distribution using the reparameterization trick\n",
    "# z_sample = sample_from_latent(z_mean, z_log_var)\n",
    "\n",
    "# Decode the sampled point to generate a reconstructed output\n",
    "reconstructed_sample = decode_sample(sampling)\n",
    "reconstructed_sample = tf.squeeze(reconstructed_sample, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "04f4f843-c1e8-46ed-99c3-fcfa7708032e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128, 32), dtype=float32, numpy=\n",
       "array([[[2.3307985e-04, 9.9998474e-01, 6.9007462e-01, ...,\n",
       "         9.9988669e-01, 5.3884083e-04, 4.4157964e-01],\n",
       "        [6.4971987e-03, 1.5548096e-03, 2.0074555e-01, ...,\n",
       "         7.7221984e-01, 9.9871063e-01, 4.2480056e-04],\n",
       "        [2.6680591e-02, 1.2697066e-03, 5.4089183e-01, ...,\n",
       "         8.8679492e-01, 9.9519497e-01, 3.3123963e-02],\n",
       "        ...,\n",
       "        [5.5085020e-05, 2.9048098e-05, 2.9102489e-01, ...,\n",
       "         6.6387671e-01, 6.4806358e-05, 6.0993427e-01],\n",
       "        [2.1871034e-04, 1.0094435e-05, 2.0955595e-01, ...,\n",
       "         6.5620542e-01, 7.8682715e-05, 6.5084594e-01],\n",
       "        [1.3981329e-03, 1.0841378e-04, 1.4787267e-01, ...,\n",
       "         6.7933577e-01, 4.2850224e-04, 6.8192679e-01]]], dtype=float32)>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8fe30c68-171e-4262-a4ec-b7f229b0c7d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'multi_head_attention_29' (type MultiHeadAttention).\n\nInput 0 of layer \"dense_161\" is incompatible with the layer: expected axis -1 of input shape to have value 32, but received input with shape (32, 1, 128)\n\nCall arguments received by layer 'multi_head_attention_29' (type MultiHeadAttention):\n  • v=tf.Tensor(shape=(32, 1, 128), dtype=float32)\n  • k=tf.Tensor(shape=(32, 1, 128), dtype=float32)\n  • q=tf.Tensor(shape=(1, 128, 32), dtype=float32)\n  • mask=tf.Tensor(shape=(1, 1, 1, 128), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     generated_tokens \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(generated_tokens, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     32\u001b[0m     generated_strings \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(token_indices)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m \u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[95], line 17\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(embedding)\u001b[0m\n\u001b[1;32m     15\u001b[0m look_ahead_mask \u001b[38;5;241m=\u001b[39m create_look_ahead_mask(tf\u001b[38;5;241m.\u001b[39mshape(decoder_input)[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     16\u001b[0m combined_mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmaximum(look_ahead_mask, dec_padding_mask)\n\u001b[0;32m---> 17\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m last_token_logits \u001b[38;5;241m=\u001b[39m decoder_output[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m     20\u001b[0m next_token \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39margmax(last_token_logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/deepmgm2/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[88], line 262\u001b[0m, in \u001b[0;36mDecoder.call\u001b[0;34m(self, x, enc_output, training, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[1;32m    259\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[0;32m--> 262\u001b[0m   x, block1, block2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdec_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mlook_ahead_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m   attention_weights[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_layer\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_block1\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m block1\n\u001b[1;32m    266\u001b[0m   attention_weights[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_layer\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_block2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m block2\n",
      "Cell \u001b[0;32mIn[88], line 189\u001b[0m, in \u001b[0;36mDecoderLayer.call\u001b[0;34m(self, x, enc_output, training, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[1;32m    186\u001b[0m attn1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(attn1, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m    187\u001b[0m out1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm1(attn1 \u001b[38;5;241m+\u001b[39m x)\n\u001b[0;32m--> 189\u001b[0m attn2, attn_weights_block2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmha2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, target_seq_len, d_model)\u001b[39;00m\n\u001b[1;32m    191\u001b[0m attn2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(attn2, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m    192\u001b[0m out2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm2(attn2 \u001b[38;5;241m+\u001b[39m out1)  \u001b[38;5;66;03m# (batch_size, target_seq_len, d_model)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[88], line 111\u001b[0m, in \u001b[0;36mMultiHeadAttention.call\u001b[0;34m(self, v, k, q, mask)\u001b[0m\n\u001b[1;32m    108\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(q)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    110\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwq(q)  \u001b[38;5;66;03m# (batch_size, seq_len, d_model)\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, seq_len, d_model)\u001b[39;00m\n\u001b[1;32m    112\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwv(v)  \u001b[38;5;66;03m# (batch_size, seq_len, d_model)\u001b[39;00m\n\u001b[1;32m    114\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_heads(q, batch_size)  \u001b[38;5;66;03m# (batch_size, num_heads, seq_len_q, depth)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'multi_head_attention_29' (type MultiHeadAttention).\n\nInput 0 of layer \"dense_161\" is incompatible with the layer: expected axis -1 of input shape to have value 32, but received input with shape (32, 1, 128)\n\nCall arguments received by layer 'multi_head_attention_29' (type MultiHeadAttention):\n  • v=tf.Tensor(shape=(32, 1, 128), dtype=float32)\n  • k=tf.Tensor(shape=(32, 1, 128), dtype=float32)\n  • q=tf.Tensor(shape=(1, 128, 32), dtype=float32)\n  • mask=tf.Tensor(shape=(1, 1, 1, 128), dtype=float32)"
     ]
    }
   ],
   "source": [
    "def decode(embedding):\n",
    "    start_token = 12\n",
    "    end_token = 13\n",
    "    max_length = 128\n",
    "    batch_size = 32\n",
    "    \n",
    "    decoder_input = tf.expand_dims([start_token] * 128, 0)\n",
    "    generated_tokens = decoder_input\n",
    "\n",
    "    embedding = tf.transpose(embedding, perm=[2, 0, 1])\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        # enc_padding_mask, combined_mask, dec_padding_mask = create_masks(decoder_input, decoder_input)\n",
    "        dec_padding_mask = create_padding_mask(decoder_input)\n",
    "        look_ahead_mask = create_look_ahead_mask(tf.shape(decoder_input)[1])\n",
    "        combined_mask = tf.maximum(look_ahead_mask, dec_padding_mask)\n",
    "        decoder_output = transformer.decoder(decoder_input, embedding, False, combined_mask, dec_padding_mask)\n",
    "        \n",
    "        last_token_logits = decoder_output[:, -1, :]\n",
    "        next_token = tf.argmax(last_token_logits, axis=-1)\n",
    "        generated_tokens = tf.concat([generated_tokens, tf.expand_dims(next_token, 1)], axis=-1)\n",
    "        \n",
    "        # Stop decoding if the end-of-sequence token is generated for all samples\n",
    "        if tf.reduce_all(next_token == end_token):\n",
    "            break\n",
    "    \n",
    "        # Update the decoder input for the next step\n",
    "        decoder_input = generated_tokens\n",
    "    \n",
    "    # Remove the batch dimension from the generated tokens\n",
    "    generated_tokens = tf.squeeze(generated_tokens, axis=0)\n",
    "    generated_strings = tokenizer.decode(token_indices).replace(' ', '')\n",
    "\n",
    "decode(enc_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa966a3-9c3b-4834-a4e8-c62aa6692b68",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Previous Attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f792fa6-095a-4ce9-99be-dea1f368e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cb2_embeddings = np.load(\"./data/CB2_EMBED.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef7336-2099-4cba-b119-d3c1ca027333",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ROWS = 104\n",
    "MAX_COLUMNS = 512\n",
    "\n",
    "cb2_embeddings = list( cb2_embeddings.values() )\n",
    "X_train, x_test = train_test_split(cb2_embeddings, test_size=0.3, random_state=17)\n",
    "\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, padding='post', maxlen=MAX_ROWS)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, padding='post', maxlen=MAX_ROWS)\n",
    "X_train = tf.expand_dims(X_train, axis=-1)\n",
    "x_test = tf.expand_dims(x_test, axis=-1)\n",
    "\n",
    "X_train.shape, x_test.shape, X_train[1].shape, X_train[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc74440-5f5f-419b-af53-71287a6a412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.cast(X_train, dtype=tf.float32)\n",
    "X_train = X_train / tf.norm(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f9730-9a17-4405-87d7-f40b204f2743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7e1b3-3015-4b66-a7d0-35c10f932170",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480bf04f-ef85-4a5a-a982-b638d6613792",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(MAX_ROWS, MAX_COLUMNS, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9715168b-fc2a-4bf8-8108-d0c31c201214",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(26 * 128 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((26, 128, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b6615-8150-43af-958c-1c33b022b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b943f79-8a0e-4a52-a281-a2eec59d9574",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.legacy.Adam())\n",
    "vae.fit(X_train, epochs=30, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc1399-ae4f-478f-b637-980eb9d21638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5bb8a9-e19f-4919-9044-c6181d34324b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ca4675-7e70-4a0e-9a2c-ee5307320652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c980cde-8ded-43b6-adaa-4a7e0d22e21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f01fce-7282-4b2d-82fa-88247edca40a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dd4cd8-de56-4a0d-a8be-202f8bf6aaf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec2bce7-e6af-4adc-95d0-821866179204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4373ad5b-7598-4750-a07c-51fe0450620a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b77f27a-44c7-480e-9186-ec33f683f3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777bc94f-87db-4922-9679-6fbaeb0b3e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3273745-5aae-4a7e-82a8-a7d67a8c5e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1e05f2-0f82-4ce3-9bc6-aabe6340f3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8c4198-391f-4a30-8121-611fa1f003cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a654370-4999-402d-a9a8-ee238b93e25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835dc261-df72-44de-89e8-c0b6d7bab640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a215d530-7c18-4c29-86ff-5e698878a7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c361458-a1ca-4a71-ad9f-51c27824adc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b92202d-5404-49ca-bbe5-c185c19b40e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad4c1c-63c5-4f6d-820a-e1fd1e9c5162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a48b7a1-9e01-4b49-9824-795862130fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256ca872-7d1a-4929-bcbc-9410c41ff4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a41cd2-cba6-4047-a444-649dac42618e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd11993-91ab-438c-87a5-bba5bb6965f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2efea33-5bb2-4745-a526-2fcc3b3130d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195abaa-f091-4bb3-ada1-d6478ff25f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f00b41-bbbf-4529-9f22-ca855f90c10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c48686f-a7c2-40bc-8ce0-13553b9b6bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d2ebe2-aa4c-4033-b022-7339fc637913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5c11e2-2bef-4d3f-9361-a16fd819e9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d03f6f-1c76-40e2-8e88-1918bd145ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d767f-a390-428e-a509-12aec097fba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f04e891-ebae-442c-b240-9ab3b5b70205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf5b32f-cd1a-45dd-81a9-6e70bac05dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b77e746-0dfd-48c5-ae0e-d49efe5426a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c69b9a6-802a-4210-9aa8-78c36067f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Reshape, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (104, 512)\n",
    "latent_dim = 64  # Adjust this based on your requirements\n",
    "\n",
    "# Encoder network\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Dense(256, activation='relu')(inputs)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(x)\n",
    "z_log_var = Dense(latent_dim)(x)\n",
    "\n",
    "# Reparameterization trick for the sampling layer\n",
    "# Update the sampling function\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch_size = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch_size, dim, latent_dim))  # <-- Generate noise with the right shape\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "# Decoder network\n",
    "decoder_input = Input(shape=(MAX_ROWS, latent_dim,))\n",
    "x = Dense(128, activation='relu')(decoder_input)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "outputs = Dense(input_shape[1], activation='sigmoid')(x)\n",
    "\n",
    "# Define the encoder and decoder models\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "decoder = Model(decoder_input, outputs, name='decoder')\n",
    "\n",
    "# Custom VAE layer for loss calculation\n",
    "class VaeLossLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(VaeLossLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def vae_loss(self, y_true, y_pred):\n",
    "        reconstruction_loss = K.mean(binary_crossentropy(y_true, y_pred)) * input_shape[0] * input_shape[1]\n",
    "        kl_loss = -0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return reconstruction_loss + kl_loss\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y_true, y_pred = inputs\n",
    "        loss = self.vae_loss(y_true, y_pred)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        return y_true  # We return y_true to maintain the original output\n",
    "\n",
    "# Combine the encoder and decoder to form the VAE model with the custom loss layer\n",
    "vae_outputs = decoder(encoder(inputs)[2])\n",
    "vae_loss_layer = VaeLossLayer(name='vae_loss_layer')([inputs, vae_outputs])\n",
    "vae = Model(inputs, vae_outputs)\n",
    "\n",
    "# Manually compute the loss and gradients for custom training loop\n",
    "optimizer = tf.keras.optimizers.legacy.Adam()\n",
    "def compute_loss(y_true, y_pred):\n",
    "    reconstruction_loss = K.mean(binary_crossentropy(y_true, y_pred)) * input_shape[0] * input_shape[1]\n",
    "    kl_loss = -0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return reconstruction_loss + kl_loss\n",
    "\n",
    "@tf.function\n",
    "def train_step(x):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        z_mean, z_log_var, z = encoder(x, training=True)  # Use the encoder model directly\n",
    "        x_pred = decoder(z, training=True)  # Use the decoder model directly\n",
    "\n",
    "        # Compute the reconstruction loss\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            binary_crossentropy(x, x_pred)\n",
    "        ) * input_shape[0] * input_shape[1]\n",
    "\n",
    "        # Compute the KL divergence loss (for each sample in the batch)\n",
    "        kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "\n",
    "        # Total loss\n",
    "        total_loss = reconstruction_loss + tf.reduce_mean(kl_loss) + tf.reduce_sum(vae.losses)\n",
    "\n",
    "    # Compute gradients and update the model\n",
    "    gradients = tape.gradient(total_loss, vae.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, vae.trainable_variables))\n",
    "\n",
    "    return total_loss\n",
    "    \n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8fe888-ef88-42d9-86dc-28e8fdd1e0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a430e72-d663-4abd-8aae-3ea7e21e6129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9081f9fb-f6a6-43b2-a02d-095885a82909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc0419b-0b71-40fd-87ac-e6a4840c809e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88503b3c-8ce9-4696-ad58-dd83c75f63f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Reshape, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (104, 512)\n",
    "latent_dim = 64  # Adjust this based on your requirements\n",
    "\n",
    "# Encoder network\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Dense(256, activation='relu')(inputs)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(x)\n",
    "z_log_var = Dense(latent_dim)(x)\n",
    "\n",
    "# Reparameterization trick for the sampling layer\n",
    "# Update the sampling function\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch_size = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch_size, dim, latent_dim))  # <-- Generate noise with the right shape\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "# Decoder network\n",
    "decoder_input = Input(shape=(MAX_ROWS, latent_dim,))\n",
    "x = Dense(128, activation='relu')(decoder_input)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "outputs = Dense(input_shape[1], activation='sigmoid')(x)\n",
    "\n",
    "# Define the encoder and decoder models\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "decoder = Model(decoder_input, outputs, name='decoder')\n",
    "\n",
    "# Custom VAE layer for loss calculation\n",
    "class VaeLossLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(VaeLossLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def vae_loss(self, y_true, y_pred):\n",
    "        reconstruction_loss = K.mean(binary_crossentropy(y_true, y_pred)) * input_shape[0] * input_shape[1]\n",
    "        kl_loss = -0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return reconstruction_loss + kl_loss\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y_true, y_pred = inputs\n",
    "        loss = self.vae_loss(y_true, y_pred)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        return y_true  # We return y_true to maintain the original output\n",
    "\n",
    "# Combine the encoder and decoder to form the VAE model with the custom loss layer\n",
    "vae_outputs = decoder(encoder(inputs)[2])\n",
    "vae_loss_layer = VaeLossLayer(name='vae_loss_layer')([inputs, vae_outputs])\n",
    "vae = Model(inputs, vae_outputs)\n",
    "\n",
    "# Manually compute the loss and gradients for custom training loop\n",
    "optimizer = tf.keras.optimizers.legacy.Adam()\n",
    "def compute_loss(y_true, y_pred):\n",
    "    reconstruction_loss = K.mean(binary_crossentropy(y_true, y_pred)) * input_shape[0] * input_shape[1]\n",
    "    kl_loss = -0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return reconstruction_loss + kl_loss\n",
    "\n",
    "@tf.function\n",
    "def train_step(x):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        z_mean, z_log_var, z = encoder(x, training=True)  # Use the encoder model directly\n",
    "        x_pred = decoder(z, training=True)  # Use the decoder model directly\n",
    "\n",
    "        # Compute the reconstruction loss\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            binary_crossentropy(x, x_pred)\n",
    "        ) * input_shape[0] * input_shape[1]\n",
    "\n",
    "        # Compute the KL divergence loss (for each sample in the batch)\n",
    "        kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "\n",
    "        # Total loss\n",
    "        total_loss = reconstruction_loss + tf.reduce_mean(kl_loss) + tf.reduce_sum(vae.losses)\n",
    "\n",
    "    # Compute gradients and update the model\n",
    "    gradients = tape.gradient(total_loss, vae.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, vae.trainable_variables))\n",
    "\n",
    "    return total_loss\n",
    "    \n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70e3cca-c540-4338-9c74-fa58483be8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "num_batches = len(X_train) // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        x_batch = X_train[start_idx:end_idx]\n",
    "        loss = train_step(x_batch)\n",
    "        print(f\"Batch {batch_idx+1}/{num_batches}, Loss: {loss.numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf86b3-d6ac-467d-b797-3a6f9d044ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new samples using the VAE\n",
    "random_samples = tf.random.normal(shape=(1, 104, latent_dim))\n",
    "generated_images = decoder(random_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b084a0-3eb2-413a-9fd2-7061afe71dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e8ecd-354b-45ed-825e-72d8b8820d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548c9694-add9-4ecd-a1ae-e2308df11291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a1923d-b3f3-4a03-8531-6411353ac2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaab157-b881-451c-8550-2f2b94f64fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (104, 512)\n",
    "latent_dim = 64  # Adjust this based on your requirements\n",
    "\n",
    "# Encoder network\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Dense(256, activation='relu')(inputs)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(x)\n",
    "z_log_var = Dense(latent_dim)(x)\n",
    "\n",
    "# Reparameterization trick for the sampling layer\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.0, stddev=1.0)\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "# Decoder network\n",
    "decoder_input = Input(shape=(MAX_ROWS, latent_dim,))\n",
    "x = Dense(128, activation='relu')(decoder_input)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "outputs = Dense(input_shape[1], activation='sigmoid')(x)\n",
    "# outputs = Reshape(input_shape)(outputs)\n",
    "\n",
    "# Define the encoder and decoder models\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "decoder = Model(decoder_input, outputs, name='decoder')\n",
    "\n",
    "# Combine the encoder and decoder to form the VAE model\n",
    "vae_outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, vae_outputs, name='vae')\n",
    "\n",
    "# Define the VAE loss function\n",
    "def vae_loss(y_true, y_pred):\n",
    "    reconstruction_loss = K.mean(binary_crossentropy(y_true, y_pred)) * input_shape[0] * input_shape[1]\n",
    "    kl_loss = -0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return reconstruction_loss + kl_loss\n",
    "\n",
    "# Compile the VAE model with the loss function directly\n",
    "vae.compile(optimizer='adam', loss=vae_loss)\n",
    "\n",
    "# Print the model summary\n",
    "vae.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8a9960-62e3-4e7b-a594-cdf31c52e500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the VAE\n",
    "vae.fit(X_train, X_train, epochs=30, batch_size=32)\n",
    "\n",
    "# Generate new samples using the VAE\n",
    "random_samples = tf.random.normal(shape=(10, latent_dim))\n",
    "generated_images = vae.decoder(random_samples)\n",
    "\n",
    "# Optionally, you can save and load the trained model\n",
    "# vae.save('vae_model')\n",
    "# vae = tf.keras.models.load_model('vae_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644da91b-e70e-4d9b-b663-becc82b16c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abfac08-b26c-4289-ab5a-6c24428ec35c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95c9adf-82da-4041-8f0b-d5260831f329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8681f79b-2164-4c02-b8bb-bdbc9e887b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(tf.keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Encoder network\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(MAX_ROWS, MAX_COLUMNS, 1)),\n",
    "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "        ])\n",
    "\n",
    "        # Decoder network\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units=(MAX_ROWS // 8) * (MAX_COLUMNS // 8) * 32, activation='relu'),  # Adjust units based on desired intermediate shape\n",
    "            tf.keras.layers.Reshape(target_shape=(MAX_ROWS // 8, MAX_COLUMNS // 8, 32)),  # Adjust target_shape based on desired intermediate shape\n",
    "            tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=(2, 2), padding='SAME', activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3, strides=(2, 2), padding='SAME', activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=(2, 2), padding='SAME', activation='sigmoid'),\n",
    "        ])\n",
    "\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=tf.shape(mean))\n",
    "        return eps * tf.exp(logvar * 0.5) + mean\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def call(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        reconstructed = self.decode(z)\n",
    "        \n",
    "        # Crop the reconstructed output to match the input size (106, 512)\n",
    "        target_height, target_width = MAX_ROWS, MAX_COLUMNS\n",
    "        reconstructed = tf.image.crop_to_bounding_box(reconstructed, \n",
    "                                                      0, 0, target_height, target_width)\n",
    "        \n",
    "        return reconstructed, mean, logvar\n",
    "\n",
    "# Define the loss function for VAE\n",
    "def vae_loss(x, reconstructed):\n",
    "    # Reconstruction loss (binary cross-entropy)\n",
    "    reconstruction_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(tf.keras.backend.flatten(x),\n",
    "                                                                              tf.keras.backend.flatten(reconstructed)))\n",
    "\n",
    "    # KL divergence loss\n",
    "    kl_loss = -0.5 * tf.reduce_sum(1 + reconstructed[2] - tf.square(reconstructed[1]) - tf.exp(reconstructed[2]), axis=-1)\n",
    "    kl_loss = tf.reduce_mean(kl_loss)\n",
    "\n",
    "    return reconstruction_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee34d35-77a1-4b62-8263-0183df2f3a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters and create the VAE model\n",
    "latent_dim = 32\n",
    "vae = VariationalAutoencoder(latent_dim)\n",
    "vae.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), loss=vae_loss)\n",
    "vae.build( (None, MAX_ROWS, MAX_COLUMNS) )\n",
    "\n",
    "# vae.summary()\n",
    "\n",
    "# vae.encoder.summary()\n",
    "vae.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977a38e0-b597-42a2-ac5e-f2b9692b1394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "# Train the VAE\n",
    "vae.fit(X_train, X_train, epochs=30, batch_size=32)\n",
    "\n",
    "# Generate new samples using the VAE\n",
    "random_samples = tf.random.normal(shape=(10, latent_dim))\n",
    "generated_images = vae.decoder(random_samples)\n",
    "\n",
    "# Optionally, you can save and load the trained model\n",
    "# vae.save('vae_model')\n",
    "# vae = tf.keras.models.load_model('vae_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
